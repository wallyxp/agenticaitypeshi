{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "563cf463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd410eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758744520.402359 2662279 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63ce7b",
   "metadata": {},
   "source": [
    "**read about reducer functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f188b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from typing_extensions import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "#reducer functio -> adds some kind of validation to messages\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State) -> State:\n",
    "    return {'messages': [llm.invoke(state['messages'])]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node('chatbot_node', chatbot)\n",
    "\n",
    "builder.add_edge(START, \"chatbot_node\")\n",
    "builder.add_edge(\"chatbot_node\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30a0b92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Who is the current president of the United States?', additional_kwargs={}, response_metadata={}, id='7228b767-95ce-42f2-8763-a30d488beab9'),\n",
       " AIMessage(content='The current president of the United States is **Joe Biden**.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--44592b85-d3a5-416f-bcd5-834c7177bd22-0', usage_metadata={'input_tokens': 11, 'output_tokens': 64, 'total_tokens': 75, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 52}})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = {'role': 'user', 'content':'Who is the current president of the United States?'}\n",
    "response = graph.invoke({'messages':[message]})\n",
    "\n",
    "response[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9149df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:  Hello! How can I help you today?\n",
      "Bot:  To find the square of 69, you multiply 69 by itself:\n",
      "\n",
      "69 * 69 = 4761\n",
      "\n",
      "So, the square of 69 is **4761**.\n",
      "Bot:  As an AI, I don't have personal feelings or opinions like \"liking\" or \"disliking\" things.\n",
      "\n",
      "However, I can tell you that Siri is a very well-known and widely used AI assistant, especially popular on Apple devices. It's designed to help users with a variety of tasks through voice commands, which is a great use of AI technology to make devices more accessible and functional.\n",
      "\n",
      "We are both examples of AI designed to assist users, just in different ways and often on different platforms!\n",
      "Bot:  I am a large language model, trained by Google.\n",
      "\n",
      "My purpose is to provide information, answer your questions, help with creative tasks, and assist you in various ways through text-based communication. I don't have a name, personal feelings, or a physical form.\n"
     ]
    }
   ],
   "source": [
    "state = None\n",
    "\n",
    "while True:\n",
    "    in_message = input(\"You : \")\n",
    "\n",
    "    if in_message.lower() in {\"quit\", \"exit\"}:\n",
    "        break\n",
    "\n",
    "    if state == None:\n",
    "        state: State = {\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": in_message}]\n",
    "        }\n",
    "    else:\n",
    "        state[\"messages\"].append({\"role\": \"user\", \"content\": in_message})\n",
    "\n",
    "\n",
    "    state = graph.invoke(state)\n",
    "    print(\"Bot: \", state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df536c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
